# 模型缓存功能实现文档

## 1. 功能概述

本文档详细介绍如何为 Open WebUI 项目的 `/api/models` 接口添加缓存功能，以提高接口响应速度和系统性能。

### 1.1 问题描述

- `/api/models` 接口加载缓慢
- 每次调用都会从外部 API 获取模型列表
- 每次调用都会进行大量的计算和处理

### 1.2 解决方案

- 添加缓存机制，减少重复计算和外部 API 调用
- 提供手动刷新缓存的功能，确保数据同步
- 优化代码结构，提高性能

## 2. 后端实现

### 2.1 添加缓存装饰器

修改 `backend/open_webui/utils/models.py` 文件，为 `get_all_models` 函数添加缓存装饰器：

```python
# 在文件顶部添加导入
from aiocache import cached

# 修改 get_all_models 函数
@cached(ttl=3600)  # 缓存 1 小时
async def get_all_models(request, user: UserModel = None):
    # 原函数实现
```

### 2.2 添加缓存刷新接口

修改 `backend/open_webui/routers/utils.py` 文件，添加缓存刷新接口：

```python
from fastapi import APIRouter, Depends, Request
from open_webui.utils.models import get_all_models
from open_webui.utils.auth import get_admin_user

router = APIRouter()

@router.post("/refresh-models-cache")
async def refresh_models_cache(request: Request, user=Depends(get_admin_user)):
    # 清除缓存
    from aiocache import Cache
    cache = Cache()
    await cache.clear()

    # 重新加载模型
    await get_all_models(request, user=user)

    return {"status": "success", "message": "Models cache refreshed successfully"}
```

### 2.3 配置缓存存储

如果需要使用 Redis 作为缓存存储（可选），修改 `backend/open_webui/config.py` 文件：

```python
# 添加 Redis 缓存配置
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")
```

修改 `backend/open_webui/utils/models.py` 文件：

```python
from aiocache import cached, Cache

@cached(ttl=3600, cache=Cache.from_url(os.getenv("REDIS_URL", "memory")))
async def get_all_models(request, user: UserModel = None):
    # 原函数实现
```

## 3. 前端实现

### 3.1 添加刷新缓存按钮

在管理后台页面添加刷新缓存按钮，例如在 `src/lib/components/admin/AdminPanel.svelte` 文件中：

```svelte
<!-- 在管理员操作区域添加 -->
<div class="admin-actions">
	<button
		class="px-4 py-2 bg-blue-500 hover:bg-blue-600 text-white rounded-lg transition-colors"
		on:click={async () => {
			try {
				const response = await fetch('/api/v1/utils/refresh-models-cache', {
					method: 'POST',
					headers: {
						Authorization: `Bearer ${localStorage.token}`
					}
				});

				if (response.ok) {
					toast.success('模型缓存刷新成功');
				} else {
					toast.error('模型缓存刷新失败');
				}
			} catch (error) {
				toast.error('模型缓存刷新失败');
			}
		}}
	>
		刷新模型缓存
	</button>
</div>
```

### 3.2 添加缓存状态显示

在模型列表页面添加缓存状态显示：

```svelte
<!-- 在 src/lib/components/workspace/Personalapp.svelte 文件中添加 -->
<div class="model-cache-status">
	<p class="text-sm text-gray-500">
		模型列表已缓存，上次更新时间：{new Date().toLocaleString()}
	</p>
</div>
```

## 4. 测试和验证

### 4.1 性能测试

1. **测试工具**：使用浏览器开发者工具或 Postman
2. **测试步骤**：
   - 第一次调用 `/api/models` 接口，记录响应时间
   - 第二次调用 `/api/models` 接口，记录响应时间
   - 比较两次响应时间，验证缓存效果

### 4.2 功能测试

1. **测试缓存刷新**：
   - 调用 `/api/v1/utils/refresh-models-cache` 接口
   - 验证接口返回成功
   - 再次调用 `/api/models` 接口，验证返回最新数据

2. **测试缓存过期**：
   - 等待缓存过期（1小时）
   - 调用 `/api/models` 接口，验证是否重新加载数据

## 5. 优化建议

### 5.1 代码优化

1. **批量加载函数模块**：

```python
# 批量加载函数模块
action_ids = list(set([action_id for model in models for action_id in model.get('action_ids', [])] + global_action_ids))
function_modules = {}
for action_id in action_ids:
    if action_id in enabled_action_ids:
        if action_id not in request.app.state.FUNCTIONS:
            function_module, _, _ = load_function_module_by_id(action_id)
            request.app.state.FUNCTIONS[action_id] = function_module
        function_modules[action_id] = request.app.state.FUNCTIONS[action_id]
```

2. **异步并行处理**：

```python
# 使用 asyncio.gather 并行处理
import asyncio

async def get_all_base_models(request, user: UserModel = None):
    tasks = []
    if request.app.state.config.ENABLE_OPENAI_API:
        tasks.append(openai.get_all_models(request, user=user))
    if request.app.state.config.ENABLE_OLLAMA_API:
        tasks.append(ollama.get_all_models(request, user=user))
    tasks.append(get_function_models(request))

    results = await asyncio.gather(*tasks)

    # 处理结果
```

### 5.2 缓存策略优化

1. **调整缓存时间**：
   - 根据实际使用情况调整 `ttl` 值
   - 频繁更新的环境可以设置较短的缓存时间

2. **使用 Redis 缓存**：
   - 对于生产环境，建议使用 Redis 作为缓存存储
   - 提高缓存可靠性和分布式部署支持

3. **缓存预热**：
   - 在应用启动时预加载模型列表
   - 减少首次访问的响应时间

## 6. 注意事项

### 6.1 数据一致性

- 缓存可能导致数据与实际不同步
- 建议设置合理的缓存过期时间
- 提供手动刷新缓存的功能

### 6.2 内存使用

- 缓存会占用一定的内存空间
- 对于大量模型的情况，建议使用 Redis 缓存

### 6.3 错误处理

- 添加缓存相关的错误处理
- 确保在缓存失效时能够正常工作

## 7. 部署和监控

### 7.1 部署步骤

1. **安装依赖**：

   ```bash
   pip install aiocache
   ```

2. **配置环境变量**（可选）：

   ```bash
   export REDIS_URL=redis://localhost:6379/0
   ```

3. **重启服务**：
   ```bash
   # 重启后端服务
   ```

### 7.2 监控指标

- **响应时间**：监控 `/api/models` 接口的响应时间
- **缓存命中率**：监控缓存使用情况
- **错误率**：监控缓存相关的错误

## 8. 总结

通过本文档的实现步骤，您可以显著提高 `/api/models` 接口的响应速度，改善用户体验，同时保持系统的可靠性和数据的一致性。缓存功能的添加是一个简单但有效的优化手段，适合在生产环境中实施。

## 9. 技术支持

如有任何问题，请参考相关文档或寻求社区支持。
